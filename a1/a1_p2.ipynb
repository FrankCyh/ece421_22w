{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression in TensorFlow [20 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Computational Graph [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    return np.exp(s) / (1+ np.exp(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction (w, b, x, label): # evaluate accuracy rate\n",
    "    prob = sigmoid(np.dot(x, w) + b)\n",
    "    predict = prob > 0.5\n",
    "    correct = np.where(predict == label)[0].size # how many correct\n",
    "    return correct / np.shape(predict)[0] # correct estimation out of all sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.14.0\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGraph(beta1, beta2, epsilon, alpha):\n",
    "    w = tf.Variable(tf.random.truncated_normal([28 * 28, 1], mean=0, stddev=0.5, dtype=tf.float32, trainable=True))\n",
    "    b = tf.Variable(tf.zeros(1), name='b', dtype=tf.float32, trainable=True)\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y = tf.placeholder(tf.float32, [None, 1])\n",
    "    reg = tf.placeholder(tf.float32)\n",
    "\n",
    "    logits = tf.matmul(x, w) + b\n",
    "\n",
    "    loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=y, logits=logits) + reg * tf.nn.l2_loss(w) #latter term returns half the l2 norm of w\n",
    "\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(alpha, beta1, beta2, epsilon).minimize(loss)\n",
    "\n",
    "    return w, b, x, y, reg, loss, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves2(reg, alpha, batchsize, b1, b2, ep, train_acc, train_loss, val_acc, val_loss, test_acc, test_loss, plot_test):\n",
    "    n = len(train_acc)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title('TF Model Loss for alpha={}, reg={}, batch={}, b1={}, b2={}, eps={}'.format(alpha,reg,batchsize,b1,b2,ep))\n",
    "    plt.plot(range(1,1+n), train_loss, label=\"Train\")\n",
    "    plt.plot(range(1,1+n), val_loss, label=\"Validation\")\n",
    "    if plot_test:\n",
    "        plt.plot(range(1,1+n), test_loss, label=\"Test\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    print(\"Final Training Loss: {}\".format(train_loss[-1]))\n",
    "    print(\"Final Validation Loss: {}\".format(val_loss[-1]))\n",
    "    if plot_test:\n",
    "        print(\"Final Testing Loss: {}\".format(test_loss[-1]))\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title('TF Model Accuracy for alpha={}, reg={}, batch={}, b1={}, b2={}, eps={}'.format(alpha,reg,batchsize,b1,b2,ep))\n",
    "    plt.plot(range(1,1+n), train_acc, label=\"Train\")\n",
    "    plt.plot(range(1,1+n), val_acc, label=\"Validation\")\n",
    "    if plot_test:\n",
    "        plt.plot(range(1,1+n), test_acc, label=\"Test\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "    if plot_test:\n",
    "        print(\"Final Testing Loss: {}\".format(test_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_sgd(train_data, valid_data, test_data, trainTarget,validTarget, testTarget, epochs, bs, reg, lr, b1, b2, ep, plot_test):\n",
    "    tf.compat.v1.set_random_seed(421)\n",
    "    W, b, pred, y, loss, optim, d, r = buildGraph(lr,b1,b2,ep)\n",
    "    init_op = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "    N = train_data.shape[0]\n",
    "    batches = int(N/bs)\n",
    "    train_accs, val_accs, train_losses, val_losses, test_accs, test_losses = [], [], [], [], [], []\n",
    "\n",
    "    train_data = np.reshape(train_data, (3500, -1))\n",
    "    valid_data = np.reshape(valid_data, (100, -1))\n",
    "    test_data = np.reshape(test_data, (145, -1))\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "\n",
    "        for e in range(0, epochs, 1):\n",
    "            shuffled = np.random.permutation(N)\n",
    "            train_data, trainTarget = train_data[shuffled], trainTarget[shuffled]\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_acc = 0.0\n",
    "\n",
    "            for iter in range(0, batches, 1):\n",
    "                iter *= bs\n",
    "                _, train_predicts, batch_loss = sess.run([optim, pred, loss], feed_dict={r:reg, d:train_data[iter:iter+bs], y:trainTarget[iter:iter+bs]})\n",
    "                batch_acc = evaluate_prediction(train_predicts, trainTarget[iter:iter+bs])\n",
    "                train_loss += batch_loss\n",
    "                train_acc += batch_acc\n",
    "\n",
    "            train_acc /= batches\n",
    "            train_loss /= batches\n",
    "\n",
    "            valid_predicts,valid_loss = sess.run([pred, loss], feed_dict={r:reg, d:valid_data, y:validTarget})\n",
    "            valid_acc = evaluate_prediction(valid_predicts, validTarget)\n",
    "\n",
    "            test_predicts,test_loss = sess.run([pred, loss], feed_dict={r:reg, d:test_data, y:testTarget})\n",
    "            test_acc = evaluate_prediction(test_predicts, testTarget)\n",
    "                \n",
    "            train_accs.append(train_acc)\n",
    "            train_losses.append(train_loss)\n",
    "            val_accs.append(valid_acc)\n",
    "            val_losses.append(valid_loss)\n",
    "            test_accs.append(test_acc)\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        sess.close()\n",
    "\n",
    "    plot_curves2(reg, lr, bs, b1, b2, ep, train_accs, train_losses, val_accs, val_losses, test_accs, test_losses, plot_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tn/gxktm79j0klgcyy6t4_rb0lc0000gn/T/ipykernel_2916/1517976775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestTarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loadData' is not defined"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data, trainTarget, validTarget, testTarget = loadData()\n",
    "\n",
    "epochs = 700\n",
    "batchsize = 500\n",
    "reg = 0\n",
    "lr = 0.001\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "ep = 1e-08\n",
    "\n",
    "tf_sgd(train_data, valid_data, test_data, trainTarget,validTarget, testTarget, epochs, batchsize, reg, lr, b1, b2, ep, 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2360a000a0cfe5081460c17beecfe8caa8ffc0b971d04eec0b4ad72260c01bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
